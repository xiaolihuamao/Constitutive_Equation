{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单流体嵌入网络的PFGs聚合物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random, genfromtxt\n",
    "from IPython.display import display\n",
    "from matplotlib import rc\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.ticker as mticker\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "device=torch.device(\"cuda\")\n",
    "# 检查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 使用 GPU\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # 使用 CPU\n",
    "    print(\"No GPU available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据类型\n",
    "DTYPE = torch.float32\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "df = {}\n",
    "# 读取 Excel 文件中的所有 sheet\n",
    "url_hf = 'Data/DifferComponent_data.xlsm'\n",
    "df_HF = pd.read_excel(url_hf, sheet_name=None)\n",
    "# 初始化训练集和验证集\n",
    "train_set = pd.DataFrame()  # 用于存储训练集\n",
    "valid_set = pd.DataFrame()  # 用于存储验证集\n",
    "\n",
    "# 遍历所有 sheet\n",
    "for sheet_name, df in df_HF.items():\n",
    "    # 移除包含 NaN 的行\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # 根据 sheet_name 划分数据集\n",
    "    if sheet_name == 'b2': \n",
    "        valid_set = df  # sheet_name='b1' 的视为验证集\n",
    "    if sheet_name!='b1':\n",
    "        train_set = pd.concat([train_set, df], ignore_index=True)  # 其他 sheet 拼接为训练集\n",
    "\n",
    "# 提取目标变量\n",
    "y1_train = train_set['lossF'].to_numpy()\n",
    "y1_valid = valid_set['lossF'].to_numpy()\n",
    "\n",
    "# 提取特征变量\n",
    "feature_columns = ['AngFreq', 'Mn1', 'Mn2', 'Mn3',  \n",
    "                   'Mn11', 'Mn22', 'Mn33']\n",
    "X_train = train_set[feature_columns].to_numpy()\n",
    "X_valid = valid_set[feature_columns].to_numpy()\n",
    "\n",
    "# 计算哈达玛积\n",
    "def add_hadamard_features(X):\n",
    "    \"\"\"\n",
    "    计算哈达玛积并拼接新特征。\n",
    "\n",
    "    参数:\n",
    "        X (numpy.ndarray): 输入的特征矩阵，形状为 (n_samples, n_features)。\n",
    "                          列顺序必须为 ['AngFreq', 'Mn1', 'Mn2', 'Mn3', 'Mn11', 'Mn22', 'Mn33']。\n",
    "\n",
    "    返回:\n",
    "        numpy.ndarray: 处理后的特征矩阵，形状为 (n_samples, 4)。\n",
    "                      列顺序为 ['AngFreq', 'Mn1*Mn11', 'Mn2*Mn22', 'Mn3*Mn33']。\n",
    "    \"\"\"\n",
    "   # 计算哈达玛积\n",
    "    Mn1_Mn11 = X[:, 1] * X[:, 4]  # Mn1 * Mn11\n",
    "    Mn2_Mn22 = X[:, 2] * X[:, 5]  # Mn2 * Mn22\n",
    "    Mn3_Mn33 = X[:, 3] * X[:, 6]  # Mn3 * Mn33\n",
    "\n",
    "    # 计算交叉相乘\n",
    "    feature_1_2 = Mn1_Mn11 * Mn2_Mn22  # (Mn1 * Mn11) * (Mn2 * Mn22)\n",
    "    feature_1_3 = Mn1_Mn11 * Mn3_Mn33  # (Mn1 * Mn11) * (Mn3 * Mn33)\n",
    "    feature_2_3 = Mn2_Mn22 * Mn3_Mn33  # (Mn2 * Mn22) * (Mn3 * Mn33)\n",
    "    feature_1_2_3=Mn1_Mn11*Mn2_Mn22*Mn3_Mn33\n",
    "    # 拼接新特征\n",
    "    X_new = np.column_stack((\n",
    "        X[:, 0],  # AngFreq\n",
    "        Mn1_Mn11,\n",
    "        Mn2_Mn22,\n",
    "        Mn3_Mn33,\n",
    "        feature_1_2,\n",
    "        feature_1_3,\n",
    "        feature_2_3\n",
    "    ))\n",
    "    return X_new\n",
    "X_train=add_hadamard_features(X_train)\n",
    "X_valid=add_hadamard_features(X_valid)\n",
    "# 对频率特征进行对数化处理\n",
    "X_train[:, 0] = np.log10(X_train[:, 0])  # AngFreq 是第一个特征\n",
    "X_valid[:, 0] = np.log10(X_valid[:, 0])\n",
    "# 初始化 MinMaxScaler\n",
    "x_scaler = MinMaxScaler()  # 用于特征 X 的归一化\n",
    "y_scaler = MinMaxScaler()  # 用于目标 y 的归一化\n",
    "\n",
    "# 对 X_train 进行归一化\n",
    "X_train_normalized = x_scaler.fit_transform(X_train)\n",
    "\n",
    "# 对 y_train 进行归一化\n",
    "# 注意：y_train 需要 reshape 为二维数组，因为 MinMaxScaler 接受二维输入\n",
    "y_train_normalized = y_scaler.fit_transform(y1_train.reshape(-1, 1))\n",
    "\n",
    "# 使用保存的归一化参数对 X_valid 进行归一化\n",
    "X_valid_normalized = x_scaler.transform(X_valid)\n",
    "# 使用保存的归一化参数对 y_valid 进行归一化\n",
    "y_valid_normalized = y_scaler.transform(y1_valid.reshape(-1, 1))\n",
    "\n",
    "# 将归一化后的数据转换为 PyTorch 张量\n",
    "X_data_HF = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "y_data_HF = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "X_data_valid = torch.tensor(X_valid_normalized, dtype=torch.float32)\n",
    "y_data_valid = torch.tensor(y_valid_normalized, dtype=torch.float32)\n",
    "\n",
    "# 打印张量的形状以确认\n",
    "print(\"X_data_HF shape:\", X_data_HF.shape)\n",
    "print(\"y_data_HF shape:\", y_data_HF.shape)\n",
    "print(\"X_data_valid shape:\", X_data_valid.shape)\n",
    "print(\"y_data_valid shape:\", y_data_valid.shape)\n",
    "\n",
    "# 定义模型\n",
    "in_dim, out_dim = 7, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络的类\n",
    "class PINN_NeuralNet(nn.Module):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=0,\n",
    "                 output_dim=1,  # 默认输出维度为1\n",
    "                 num_hidden_layers=4, \n",
    "                 num_neurons_per_layer=20,\n",
    "                 activation='tanh',\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(PINN_NeuralNet, self).__init__()\n",
    "\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # 添加输入层\n",
    "        self.input_layer = nn.Linear(input_dim, num_neurons_per_layer)\n",
    "        \n",
    "        # 添加其他隐藏层\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(nn.Linear(num_neurons_per_layer, num_neurons_per_layer))\n",
    "        \n",
    "        # 添加输出层\n",
    "        self.out = nn.Linear(num_neurons_per_layer, output_dim)\n",
    "        # 设置激活函数\n",
    "        if activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == 'relu':\n",
    "            self.activation = F.relu6\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == 'linear':\n",
    "            self.activation = None\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "        \n",
    "        # 初始化权重\n",
    "        if kernel_initializer == 'glorot_normal':\n",
    "            nn.init.xavier_normal_(self.input_layer.weight)\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                nn.init.xavier_normal_(hidden_layer.weight)\n",
    "            nn.init.xavier_normal_(self.out.weight)\n",
    "        elif kernel_initializer == 'glorot_uniform':\n",
    "            nn.init.xavier_uniform_(self.input_layer.weight)\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                nn.init.xavier_uniform_(hidden_layer.weight)\n",
    "            nn.init.xavier_uniform_(self.out.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel initializer\")\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # 进入输入层\n",
    "        Z = self.input_layer(X)\n",
    "        \n",
    "        # 通过隐藏层\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            Z = hidden_layer(Z)\n",
    "            if self.activation is not None:\n",
    "                Z = self.activation(Z)\n",
    "        # 通过输出层输出\n",
    "        Z = self.out(Z)\n",
    "        \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络处理器类\n",
    "class PINNSolver():\n",
    "\n",
    "    # 类属性定义\n",
    "    def __init__(self, model_HF_nl,model_HF_1):\n",
    "        \n",
    "        self.model_HF_nl = model_HF_nl # 高保真非线性模型\n",
    "        self.model_HF_l=model_HF_1\n",
    "        self.hist =  [[], []] # loss历史列表,0:train loss ;1:valid loss\n",
    "        self.iter = 0 # 迭代次数\n",
    "        self.last_n_losses = [] # 前损失列表\n",
    "\n",
    "    # 更新损失列表   \n",
    "    def update_last_n_losses(self, loss):\n",
    "        self.last_n_losses.append(loss)\n",
    "        if len(self.last_n_losses) > 20:\n",
    "            self.last_n_losses.pop(0)\n",
    "\n",
    "    # 计算最大相对误差        \n",
    "    def ES(self):\n",
    "        if len(self.last_n_losses) < 20:\n",
    "            return 100  # a large number\n",
    "\n",
    "        current_loss = self.last_n_losses[-1]\n",
    "        max_relative_error = 100.*max([abs(current_loss - loss) / current_loss for loss in self.last_n_losses[:-1]])\n",
    "        return max_relative_error\n",
    "    \n",
    "    # 计算loss，模型核心\n",
    "    def loss_fn(self, X_data_HF, y_data_HF,X_data_valid,y_data_valid):\n",
    "        y_pred_valid_nl = self.model_HF_nl(X_data_valid)\n",
    "        y_pred_valid_l = self.model_HF_l(X_data_valid)\n",
    "        y_pred_valid = y_pred_valid_nl+y_pred_valid_l    \n",
    "        y_pred_HF_nl = self.model_HF_nl(X_data_HF)\n",
    "        y_pred_HF_l = self.model_HF_l(X_data_HF)\n",
    "        y_pred_HF = y_pred_HF_nl+y_pred_HF_l\n",
    "        \n",
    "        Loss_L2 = 1e-5 * sum(torch.sum(w_**2) for w_ in self.model_HF_nl.parameters())\n",
    "        Loss_L2+=1e-5*sum(torch.sum(w_**2) for w_ in self.model_HF_l.parameters())\n",
    "        Loss_data_HF = torch.mean((y_data_HF - y_pred_HF)**2)+Loss_L2\n",
    "        Loss_data_valid=torch.mean((y_pred_valid-y_data_valid)**2)+Loss_L2\n",
    "        \n",
    "        return Loss_data_HF,Loss_data_valid\n",
    "    # 训练核心函数，包括loss计算梯度计算和反向传播\n",
    "    def solve_with_PyTorch_optimizer(self, optimizer,data,scheduler,N=1001):\n",
    "        \"\"\"This method performs a gradient descent type optimization.\"\"\"        \n",
    "        for i in range(N):\n",
    "            # 梯度清0\n",
    "            optimizer.zero_grad()\n",
    "            # 计算loss          \n",
    "            loss,loss_valid = self.loss_fn(data[0], data[1],data[2],data[3])\n",
    "            # 反向传播计算梯度\n",
    "            loss.backward()\n",
    "            # 根据loss调度学习率\n",
    "            scheduler.step(loss)\n",
    "            # 反向传播更新权重和偏置\n",
    "            optimizer.step()\n",
    "\n",
    "            # 记录loss并计算相对误差\n",
    "            self.current_loss = loss.item()\n",
    "            self.valid_loss=loss_valid.item()\n",
    "           \n",
    "            self.max_relative_error = self.ES()\n",
    "            self.callback(self.max_relative_error,N)  # Pass max_relative_error to the callback function\n",
    "            self.update_last_n_losses(self.current_loss)\n",
    "\n",
    "            # 早停机制\n",
    "            if self.max_relative_error < 2e-3: # in %\n",
    "                print('Early stopping... \\nIt {:05,d}: Loss = {:10.4e}, Max. rel. error = {} %'.format(self.iter,\n",
    "                                                             self.current_loss,\n",
    "                                                            np.round(self.max_relative_error, 3)))\n",
    "                break\n",
    "\n",
    "    # 打印loss    \n",
    "    def callback(self, xr=None,N=1001):\n",
    "        if self.iter % 100 == 0:\n",
    "            print('It {:05,d}: Loss = {:10.4e}, Max. rel. error = {} %'.format(self.iter,\n",
    "                                                             self.current_loss,\n",
    "                                                            np.round(self.max_relative_error, 2)))\n",
    "        self.hist[0].append(self.current_loss)\n",
    "        self.hist[1].append(self.valid_loss)\n",
    "        self.iter+=1\n",
    "    \n",
    "    def plot_loss_history(self, ax=None):\n",
    "        if not ax:\n",
    "            fig = plt.figure(figsize=(7, 5))\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "        # 绘制训练集损失曲线\n",
    "        ax.semilogy(range(len(self.hist[0])), self.hist[0], 'b-', label='Training Loss')\n",
    "        \n",
    "        # 绘制验证集损失曲线\n",
    "        ax.semilogy(range(len(self.hist[1])), self.hist[1], 'g-', label='Validation Loss')\n",
    "\n",
    "        ax.set_xlabel('$n_{epoch}$')\n",
    "        ax.set_ylabel('$loss$')\n",
    "        ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{int(x):,}'))\n",
    "        ax.legend()  # 添加图例\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_HF_l = PINN_NeuralNet(input_dim=in_dim,\n",
    "                             output_dim=out_dim,\n",
    "                             num_hidden_layers=1,\n",
    "                             num_neurons_per_layer=10,\n",
    "                             activation='linear')\n",
    "model_HF_nl = PINN_NeuralNet(input_dim=in_dim,\n",
    "                             output_dim=out_dim,\n",
    "                             num_hidden_layers=5,\n",
    "                             num_neurons_per_layer=20,\n",
    "                             activation='relu')\n",
    "# 初始化 PINNSolver\n",
    "solver = PINNSolver(model_HF_nl,model_HF_l)\n",
    "\n",
    "model_HF_l.to(device)\n",
    "model_HF_nl.to(device)\n",
    "X_data_HF=X_data_HF.to(device)\n",
    "y_data_HF=y_data_HF.to(device)\n",
    "X_data_valid= X_data_valid.to(device)\n",
    "y_data_valid=y_data_valid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义学习率调度器\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(\n",
    "    list(model_HF_nl.parameters()) + list(model_HF_l.parameters()),  # 将生成器转换为列表并拼接\n",
    "    lr=lr\n",
    ")\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10, verbose=True)\n",
    "# 定义训练模式\n",
    "mode = 'PyTorch_optimizer'\n",
    "N = int(3000) + 1  # 训练迭代次数\n",
    "\n",
    "try:\n",
    "    runtime\n",
    "except NameError:\n",
    "    runtime = 0.\n",
    "\n",
    "if mode == 'PyTorch_optimizer':\n",
    "    try:\n",
    "        t0 = time()\n",
    "        solver.solve_with_PyTorch_optimizer(optimizer, [X_data_HF,y_data_HF,X_data_valid,y_data_valid],scheduler,N=N)\n",
    "        runtime += (time() - t0) / 60.\n",
    "        print('\\nRuntime: {:.3f} minutes'.format(runtime))\n",
    "    except KeyboardInterrupt:\n",
    "        runtime += (time() - t0) / 60.\n",
    "        print('\\nRuntime: {:.3f} minutes'.format(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置绘图样式\n",
    "plt.rc('font', size=18)\n",
    "plt.rc('axes', titlesize=18)\n",
    "plt.rc('axes', labelsize=18)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('legend', fontsize=18)\n",
    "plt.rc('figure', titlesize=18)\n",
    "colors = ['tab:red', 'tab:orange', '#f9c74f', 'tab:green', 'tab:cyan', 'tab:blue', 'tab:purple', 'tab:brown', 'tab:pink']\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model_HF_nl.eval()\n",
    "model_HF_l.eval()\n",
    "# 创建图表\n",
    "fig, ax = plt.subplots(figsize=(5, 5), dpi=300)\n",
    "\n",
    "# 对训练集进行预测并绘制\n",
    "for i, sheet_name in enumerate(df_HF.keys()):\n",
    "    if sheet_name == 'b2' or sheet_name=='s' or sheet_name=='b1':\n",
    "        continue  # 跳过验证集\n",
    "    \n",
    "    # 提取当前 sheet 的数据\n",
    "    df = df_HF[sheet_name].dropna()\n",
    "    y1_train = df['lossF'].to_numpy()\n",
    "    X_train = df[feature_columns].to_numpy()\n",
    "    \n",
    "    # 对频率特征进行对数化处理\n",
    "    X_train[:, 0] = np.log10(X_train[:, 0])\n",
    "    X_train=add_hadamard_features(X_train)\n",
    "    # 对当前 sheet 的数据进行归一化\n",
    "    X_train_normalized = x_scaler.transform(X_train)\n",
    "    y_train_normalized = y_scaler.transform(y1_train.reshape(-1, 1))\n",
    "    \n",
    "    # 将数据转换为 PyTorch 张量\n",
    "    X_data_train = torch.tensor(X_train_normalized, dtype=torch.float32).to(device)\n",
    "    # 模型预测\n",
    "    y_MF_train = model_HF_nl(X_data_train)+model_HF_l(X_data_train)\n",
    "    y_MF_train_denorm = y_scaler.inverse_transform(y_MF_train.detach().cpu().numpy())\n",
    "    \n",
    "    # 绘制当前 sheet 的拟合曲线\n",
    "    ax.plot(10**X_train[:, 0], y_MF_train_denorm, color=colors[i], label=f'Train {sheet_name}')\n",
    "    ax.scatter(10**X_train[:, 0], y1_train, color=colors[i], label=f'Train {sheet_name}')\n",
    "# 对验证集进行预测并绘制\n",
    "y_MF_valid = model_HF_nl(X_data_valid)+model_HF_l(X_data_valid)\n",
    "y_MF_valid_denorm = y_scaler.inverse_transform(y_MF_valid.detach().cpu().numpy())\n",
    "\n",
    "# 绘制验证集的拟合曲线\n",
    "ax.plot(10**X_valid[:, 0], y_MF_valid_denorm, color='black', label='Validation Fit')\n",
    "\n",
    "# 绘制验证集的真实值（空心圆）\n",
    "y1_valid_denorm = y_scaler.inverse_transform(y_data_valid.cpu().numpy())\n",
    "ax.scatter(10**X_valid[:, 0], y1_valid_denorm, color='black', marker='o', facecolors='none', s=50, label='Validation Data')\n",
    "\n",
    "# 设置图表属性\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('$tan\\delta$')\n",
    "ax.set_xlabel('$\\omega$ $\\mathrm{[rad/s]}$')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# 计算验证集的 MAE、R2 和 MAPE\n",
    "mae_valid = mean_absolute_error(y1_valid_denorm, y_MF_valid_denorm)\n",
    "r2_valid = r2_score(y1_valid_denorm, y_MF_valid_denorm)\n",
    "mape_valid = np.mean(np.abs((y1_valid_denorm - y_MF_valid_denorm) / y1_valid_denorm)) * 100\n",
    "\n",
    "# 打印验证集的指标\n",
    "print(f\"Validation MAE: {mae_valid:.4f}\")\n",
    "print(f\"Validation R2: {r2_valid:.4f}\")\n",
    "print(f\"Validation MAPE: {mape_valid:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model_HF_l,'model/PFGs/model_l_AFF_pfgs')\n",
    "#torch.save(model_HF_nl,'model/PFGs/model_nl_AFF_pfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 绘制各个模型的比对图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置绘图样式\n",
    "plt.rc('font', size=18)\n",
    "plt.rc('axes', titlesize=18)\n",
    "plt.rc('axes', labelsize=18)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('legend', fontsize=18)\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "# 加载模型\n",
    "model_dnn = [torch.load('model/PFGs/model_l_dnn_pfgs'), torch.load('model/PFGs/model_nl_dnn_pfgs')]\n",
    "model_pinn = [torch.load('model/PFGs/model_l_pinn_pfgs'), torch.load('model/PFGs/model_nl_pinn_pfgs')]\n",
    "model_hadamard = [torch.load('model/PFGs/model_l_Hadamard_pfgs'), torch.load('model/PFGs/model_nl_Hadamard_pfgs')]\n",
    "model_AFF = [torch.load('model/PFGs/model_l_AFF_pfgs'), torch.load('model/PFGs/model_nl_AFF_pfgs')]\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "for model in [model_dnn, model_pinn, model_hadamard, model_AFF]:\n",
    "    model[0].eval()\n",
    "    model[1].eval()\n",
    "\n",
    "# 创建图表\n",
    "fig, ax = plt.subplots(figsize=(10, 8), dpi=300)\n",
    "\n",
    "# 定义模型名称和颜色\n",
    "model_names = ['DNN', 'PINN', 'PINN-HP', 'PINN-AFF']\n",
    "model_colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple']\n",
    "\n",
    "# 对验证集进行预测并绘制\n",
    "for model, name, color in zip([model_dnn, model_pinn, model_hadamard, model_AFF], model_names, model_colors):\n",
    "    # 模型预测\n",
    "    y_MF_valid = model[1](X_data_valid) + model[0](X_data_valid)\n",
    "    y_MF_valid_denorm = y_scaler.inverse_transform(y_MF_valid.detach().cpu().numpy())\n",
    "    \n",
    "    # 绘制验证集的拟合曲线\n",
    "    ax.plot(10**X_valid[:, 0], y_MF_valid_denorm, color=color, label=f'{name}', linewidth=3)  # 设置曲线宽度\n",
    "    \n",
    "    # 计算验证集的 MAE、R2 和 MAPE\n",
    "    mae_valid = mean_absolute_error(y1_valid_denorm, y_MF_valid_denorm)\n",
    "    r2_valid = r2_score(y1_valid_denorm, y_MF_valid_denorm)\n",
    "    mape_valid = np.mean(np.abs((y1_valid_denorm - y_MF_valid_denorm) / y1_valid_denorm)) * 100\n",
    "    \n",
    "    # 打印验证集的指标\n",
    "    print(f\"{name} Validation MAE: {mae_valid:.4f}\")\n",
    "    print(f\"{name} Validation R2: {r2_valid:.4f}\")\n",
    "    print(f\"{name} Validation MAPE: {mape_valid:.4f}%\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# 绘制验证集的真实值（空心圆）\n",
    "y1_valid_denorm = y_scaler.inverse_transform(y_data_valid.cpu().numpy())\n",
    "ax.scatter(10**X_valid[:, 0], y1_valid_denorm, color='black', marker='o', facecolors='none', s=100, label='Test')  # 设置点图大小\n",
    "\n",
    "# 设置图表属性\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('$tan\\delta$', fontsize=24)  # 设置纵坐标名称字体大小\n",
    "ax.set_xlabel('$\\omega$ $\\mathrm{[rad/s]}$', fontsize=24)  # 设置横坐标名称字体大小\n",
    "ax.tick_params(axis='both', which='major', labelsize=24)  # 设置横纵坐标刻度字体大小\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(0.35, 1), fontsize=20)  # 设置图例位置和大小\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绘制残差图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置绘图样式\n",
    "plt.rc('font', size=18)\n",
    "plt.rc('axes', titlesize=18)\n",
    "plt.rc('axes', labelsize=18)\n",
    "plt.rc('xtick', labelsize=18)\n",
    "plt.rc('ytick', labelsize=18)\n",
    "plt.rc('legend', fontsize=18)\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "# 加载模型\n",
    "model_dnn = [torch.load('model/PFGs/model_l_dnn_pfgs'), torch.load('model/PFGs/model_nl_dnn_pfgs')]\n",
    "model_pinn = [torch.load('model/PFGs/model_l_pinn_pfgs'), torch.load('model/PFGs/model_nl_pinn_pfgs')]\n",
    "model_hadamard = [torch.load('model/PFGs/model_l_Hadamard_pfgs'), torch.load('model/PFGs/model_nl_Hadamard_pfgs')]\n",
    "model_AFF = [torch.load('model/PFGs/model_l_AFF_pfgs'), torch.load('model/PFGs/model_nl_AFF_pfgs')]\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "for model in [model_dnn, model_pinn, model_hadamard, model_AFF]:\n",
    "    model[0].eval()\n",
    "    model[1].eval()\n",
    "\n",
    "# 创建残差图\n",
    "fig, ax = plt.subplots(figsize=(10, 8), dpi=300)\n",
    "\n",
    "# 定义模型名称和颜色\n",
    "model_names = ['DNN', 'PINN', 'PINN-HP', 'PINN-AFF']\n",
    "model_colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple']\n",
    "\n",
    "# 对验证集进行预测并绘制残差图\n",
    "for model, name, color in zip([model_dnn, model_pinn, model_hadamard, model_AFF], model_names, model_colors):\n",
    "    # 模型预测\n",
    "    y_MF_valid = model[1](X_data_valid) + model[0](X_data_valid)\n",
    "    y_MF_valid_denorm = y_scaler.inverse_transform(y_MF_valid.detach().cpu().numpy())\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals = y1_valid_denorm - y_MF_valid_denorm\n",
    "    \n",
    "    # 绘制残差图\n",
    "    \n",
    "    ax.scatter(X_valid[:, 0], residuals, color=color, label=f'{name}', s=50)  # 设置点图大小\n",
    "\n",
    "# 绘制 y=0 参考线\n",
    "ax.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
    "\n",
    "# 设置图表属性\n",
    "ax.set_xlabel('$lg\\omega$', fontsize=24)  # 设置横坐标名称字体大小\n",
    "ax.set_ylabel('Residuals', fontsize=24)  # 设置纵坐标名称字体大小\n",
    "ax.tick_params(axis='both', which='major', labelsize=24)  # 设置横纵坐标刻度字体大小\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(0.3, 1), fontsize=18)  # 设置图例位置和大小\n",
    "ax.set_ylim(-0.4,0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制指标图（柱状图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# 示例数据\n",
    "metrics = [f'$R^{2}$', 'MAE', 'MAPE', 'Training Time']\n",
    "dnn_values = [0.7559, 0.1080, 0.1909, 499]  # DNN 值\n",
    "pinn_values = [0.8152, 0.1003, 0.1501, 546]  # PINN 值\n",
    "pinn_hp_values = [0.8760, 0.0803, 0.1323, 508]  # PINN-HP 值\n",
    "pinn_aff_values = [0.9873, 0.0244, 0.0324, 522]  # PINN-AFF 值\n",
    "\n",
    "# 误差棒（请根据实际情况替换）\n",
    "dnn_errors = [0.008, 0.0008, 0.0008, 5]  # DNN 误差\n",
    "pinn_errors = [0.008, 0.0003, 0.0005, 4]  # PINN 误差\n",
    "pinn_hp_errors = [0.007, 0.0003, 0.0005, 3]  # PINN-HP 误差\n",
    "pinn_aff_errors = [0.006, 0.0003, 0.0005, 4]  # PINN-AFF 误差\n",
    "\n",
    "# 颜色设置\n",
    "dnn_color = 'tab:blue'  # 蓝色\n",
    "pinn_color = 'tab:orange'  # 橙色\n",
    "pinn_hp_color = 'tab:green'  # 绿色\n",
    "pinn_aff_color = 'tab:purple'  # 紫色\n",
    "\n",
    "# 创建渐变颜色映射\n",
    "def create_gradient_cmap(color1, color2, gamma=2.0, N=256):\n",
    "    cmap = LinearSegmentedColormap.from_list('custom_cmap', [color1, color2], N=N)\n",
    "    cmap._init()\n",
    "    cmap._lut[:, -1] = np.linspace(0, 1, cmap.N + 3) ** gamma\n",
    "    return cmap\n",
    "\n",
    "# 绘制柱状图\n",
    "def plot_bar(ax, x, value, error, color, label):\n",
    "    bar = ax.bar(x, value, width=0.1, color=color, yerr=error, capsize=14, label=label)\n",
    "    for rect in bar:\n",
    "        height = rect.get_height()\n",
    "        # 标签的 y 坐标 = 柱子高度 + 误差棒高度\n",
    "        label_y = height + error  # 使用当前指标的误差值\n",
    "        if metric == 'Training Time':\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2.0, label_y, f'{height:.0f}', ha='center', va='bottom', fontsize=18)\n",
    "        else:\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2.0, label_y, f'{height:.4f}', ha='center', va='bottom', fontsize=18)\n",
    "\n",
    "# 绘图\n",
    "for i, metric in enumerate(metrics):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), dpi=300)\n",
    "    x = [1, 1.2, 1.4, 1.6]  # 柱状图位置：DNN, PINN, PINN-HP, PINN-AFF\n",
    "    \n",
    "    # 创建渐变颜色\n",
    "    dnn_cmap = create_gradient_cmap('lightblue', dnn_color)\n",
    "    pinn_cmap = create_gradient_cmap('white', pinn_color)\n",
    "    pinn_hp_cmap = create_gradient_cmap('white', pinn_hp_color)\n",
    "    pinn_aff_cmap = create_gradient_cmap('white', pinn_aff_color)\n",
    "    \n",
    "    # 绘制柱状图\n",
    "    plot_bar(ax, x[0], dnn_values[i], dnn_errors[i], dnn_cmap(0.8), 'DNN')\n",
    "    plot_bar(ax, x[1], pinn_values[i], pinn_errors[i], pinn_cmap(0.8), 'PINN')\n",
    "    plot_bar(ax, x[2], pinn_hp_values[i], pinn_hp_errors[i], pinn_hp_cmap(0.8), 'PINN-HP')\n",
    "    plot_bar(ax, x[3], pinn_aff_values[i], pinn_aff_errors[i], pinn_aff_cmap(0.8), 'PINN-AFF')\n",
    "    \n",
    "    # 设置坐标轴\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['DNN', 'PINN', 'PINN-HP', 'PINN-AFF'], fontsize=24)\n",
    "    ax.set_ylabel(metric + (' [s]' if metric == 'Training Time' else ''), fontsize=24)\n",
    "    ax.set_ylim(0, max(dnn_values[i], pinn_values[i], pinn_hp_values[i], pinn_aff_values[i]) * 1.2)\n",
    "    ax.tick_params(axis='y', labelsize=24)  # 设置 y 轴刻度字体大小为 24\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
