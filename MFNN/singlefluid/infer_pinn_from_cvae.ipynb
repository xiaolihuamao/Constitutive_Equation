{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这个文件用于绘制通过PINN模型对CVAE生成的多模态解进行绘图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random, genfromtxt\n",
    "from IPython.display import display\n",
    "from matplotlib import rc\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.ticker as mticker\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/users/fxy/work/Constitutive_Equation/MFNN/singlefluid\n",
      "Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "device=torch.device(\"cuda\")\n",
    "# 检查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 使用 GPU\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # 使用 CPU\n",
    "    print(\"No GPU available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已加载用户自定义 Arial 字体\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# 检查系统是否安装了 Arial 字体\n",
    "def is_arial_available():\n",
    "    for font in fm.fontManager.ttflist:\n",
    "        if 'Arial' in font.name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 如果系统没有 Arial 字体，加载用户自定义字体\n",
    "if not is_arial_available():\n",
    "    user_font_path = os.path.expanduser('~/.local/share/fonts/ARIAL.TTF')\n",
    "    if os.path.exists(user_font_path):\n",
    "        # 添加用户字体到 Matplotlib 的字体管理器\n",
    "        fm.fontManager.addfont(user_font_path)\n",
    "        # 设置 Matplotlib 使用该字体\n",
    "        plt.rcParams['font.family'] = 'sans-serif'\n",
    "        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']\n",
    "        print(\"已加载用户自定义 Arial 字体\")\n",
    "    else:\n",
    "        print(\"未找到用户自定义 Arial 字体文件\")\n",
    "else:\n",
    "    print(\"系统已安装 Arial 字体\")\n",
    "\n",
    "# 重置 Matplotlib 的全局设置\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.rcParams['font.family'] = ['Arial']  # 设置字体为 Arial\n",
    "plt.rcParams['font.size'] = 18  # 设置全局字体大小\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算哈达玛积\n",
    "def add_hadamard_features(X):\n",
    "    \"\"\"\n",
    "    计算哈达玛积并拼接新特征。\n",
    "\n",
    "    参数:\n",
    "        X (numpy.ndarray): 输入的特征矩阵，形状为 (n_samples, n_features)。\n",
    "                          列顺序必须为 ['AngFreq', 'Mn1', 'Mn2', 'Mn3', 'Mn11', 'Mn22', 'Mn33']。\n",
    "\n",
    "    返回:\n",
    "        numpy.ndarray: 处理后的特征矩阵，形状为 (n_samples, 4)。\n",
    "                      列顺序为 ['AngFreq', 'Mn1*Mn11', 'Mn2*Mn22', 'Mn3*Mn33']。\n",
    "    \"\"\"\n",
    "   # 计算哈达玛积\n",
    "    Mn1_Mn11 = X[:, 1] * X[:, 4]  # Mn1 * Mn11\n",
    "    Mn2_Mn22 = X[:, 2] * X[:, 5]  # Mn2 * Mn22\n",
    "    Mn3_Mn33 = X[:, 3] * X[:, 6]  # Mn3 * Mn33\n",
    "\n",
    "    # 计算交叉相乘\n",
    "    feature_1_2 = Mn1_Mn11 * Mn2_Mn22  # (Mn1 * Mn11) * (Mn2 * Mn22)\n",
    "    feature_1_3 = Mn1_Mn11 * Mn3_Mn33  # (Mn1 * Mn11) * (Mn3 * Mn33)\n",
    "    feature_2_3 = Mn2_Mn22 * Mn3_Mn33  # (Mn2 * Mn22) * (Mn3 * Mn33)\n",
    "    feature_1_2_3=Mn1_Mn11*Mn2_Mn22*Mn3_Mn33\n",
    "    # 拼接新特征\n",
    "    X_new = np.column_stack((\n",
    "        X[:, 0],  # AngFreq\n",
    "        Mn1_Mn11,\n",
    "        Mn2_Mn22,\n",
    "        Mn3_Mn33,\n",
    "        feature_1_2,\n",
    "        feature_1_3,\n",
    "        feature_2_3\n",
    "    ))\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data_HF shape: torch.Size([640, 7])\n",
      "y_data_HF shape: torch.Size([640, 1])\n",
      "X_data_valid shape: torch.Size([36, 7])\n",
      "y_data_valid shape: torch.Size([36, 1])\n"
     ]
    }
   ],
   "source": [
    "#获取原始数据（主要是获取原本训练时的归一化参数，理论上不应该这样处理，另外一个是获取b4对应的频率-损耗角序列）\n",
    "\n",
    "# 设置数据类型\n",
    "DTYPE = torch.float32\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "df = {}\n",
    "# 读取 Excel 文件中的所有 sheet\n",
    "url_hf = 'Data/DifferComponent_data.xlsm'\n",
    "df_HF = pd.read_excel(url_hf, sheet_name=None)\n",
    "# 初始化训练集和验证集\n",
    "train_set = pd.DataFrame()  # 用于存储训练集\n",
    "valid_set = pd.DataFrame()  # 用于存储验证集\n",
    "\n",
    "# 遍历所有 sheet\n",
    "for sheet_name, df in df_HF.items():\n",
    "    # 移除包含 NaN 的行\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # 根据 sheet_name 划分数据集\n",
    "    if sheet_name == 'b4': \n",
    "        valid_set = df  \n",
    "    if sheet_name!='b1':\n",
    "        train_set = pd.concat([train_set, df], ignore_index=True)  # 其他 sheet 拼接为训练集\n",
    "\n",
    "# 提取目标变量\n",
    "y1_train = train_set['lossF'].to_numpy()\n",
    "y1_valid = valid_set['lossF'].to_numpy()\n",
    "\n",
    "# 提取特征变量\n",
    "feature_columns = ['AngFreq', 'Mn1', 'Mn2', 'Mn3',  \n",
    "                   'Mn11', 'Mn22', 'Mn33']\n",
    "X_train = train_set[feature_columns].to_numpy()\n",
    "X_valid = valid_set[feature_columns].to_numpy()\n",
    "\n",
    "\n",
    "X_train=add_hadamard_features(X_train)\n",
    "X_valid=add_hadamard_features(X_valid)\n",
    "# 对频率特征进行对数化处理\n",
    "X_train[:, 0] = np.log10(X_train[:, 0])  # AngFreq 是第一个特征\n",
    "X_valid[:, 0] = np.log10(X_valid[:, 0])\n",
    "# 初始化 MinMaxScaler\n",
    "x_scaler = MinMaxScaler()  # 用于特征 X 的归一化\n",
    "y_scaler = MinMaxScaler()  # 用于目标 y 的归一化\n",
    "\n",
    "# 对 X_train 进行归一化\n",
    "X_train_normalized = x_scaler.fit_transform(X_train)\n",
    "\n",
    "# 对 y_train 进行归一化\n",
    "# 注意：y_train 需要 reshape 为二维数组，因为 MinMaxScaler 接受二维输入\n",
    "y_train_normalized = y_scaler.fit_transform(y1_train.reshape(-1, 1))\n",
    "\n",
    "# 使用保存的归一化参数对 X_valid 进行归一化\n",
    "X_valid_normalized = x_scaler.transform(X_valid)\n",
    "# 使用保存的归一化参数对 y_valid 进行归一化\n",
    "y_valid_normalized = y_scaler.transform(y1_valid.reshape(-1, 1))\n",
    "\n",
    "# 将归一化后的数据转换为 PyTorch 张量\n",
    "X_data_HF = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "y_data_HF = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "X_data_valid = torch.tensor(X_valid_normalized, dtype=torch.float32)\n",
    "y_data_valid = torch.tensor(y_valid_normalized, dtype=torch.float32)\n",
    "\n",
    "# 打印张量的形状以确认\n",
    "print(\"X_data_HF shape:\", X_data_HF.shape)\n",
    "print(\"y_data_HF shape:\", y_data_HF.shape)\n",
    "print(\"X_data_valid shape:\", X_data_valid.shape)\n",
    "print(\"y_data_valid shape:\", y_data_valid.shape)\n",
    "\n",
    "# 定义模型\n",
    "in_dim, out_dim = 7, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载生成的标签数据,数据形状为: (100, 6)\n",
      "前5行数据为:\n",
      " [[19.24592718 52.19185764 79.01475178 10.93694987 20.16281711 28.81637722]\n",
      " [20.90636851 52.32290053 79.24331445  9.34296138 20.44041671 30.77089764]\n",
      " [19.90967153 52.34865365 78.65866532 10.72613774 19.16339813 28.16293688]\n",
      " [20.41629038 53.5296622  79.73968513  9.81620437 19.83479733 30.57848702]\n",
      " [19.55662918 52.95986368 79.12772338 10.3691067  19.775179   29.90009443]]\n"
     ]
    }
   ],
   "source": [
    "# 读取生成的标签数据并转换为numpy数组\n",
    "generated_labels = pd.read_excel('Data/generated_labels.xlsx', sheet_name='Generated Labels')\n",
    "label_columns = ['Mn1', 'Mn2', 'Mn3', 'Mn11', 'Mn22', 'Mn33']\n",
    "generated_labels_array = generated_labels[label_columns].to_numpy()\n",
    "print(\"成功加载生成的标签数据,数据形状为:\", generated_labels_array.shape)\n",
    "print(\"前5行数据为:\\n\", generated_labels_array[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
